{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81435c67-6b12-4332-8e32-312ee3c97d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "Starting installation...\n",
      "Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export version=`python --version |awk '{print $2}' |awk -F\".\" '{print $1$2}'`\n",
    "\n",
    "echo $version\n",
    "\n",
    "if [ $version == '36' ] || [ $version == '37' ]; then\n",
    "    echo 'Starting installation...'\n",
    "    pip3 install pyspark==2.4.8 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "elif [ $version == '38' ] || [ $version == '39' ]; then\n",
    "    pip3 install pyspark==3.1.2 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "else\n",
    "    echo 'Currently only python 3.6, 3.7 , 3.8 and 3.9 are supported, in case you need a different version please open an issue at https://github.com/IBM/claimed/issues'\n",
    "    exit -1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "623d311a-9f4d-41cb-bf61-6677a9a16376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark2pmml import PMMLBuilder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "import random\n",
    "import logging\n",
    "import re\n",
    "import shutil\n",
    "import wget\n",
    "import re\n",
    "import site\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a56bb835-ca8b-4a9f-90b5-88b0d7d60aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the parquet file you created as part of Task 3.\n",
    "data_csv = os.environ.get('data_csv', 'data.csv')\n",
    "data_parquet = os.environ.get('data_parquet', 'data.parquet')\n",
    "master = os.environ.get('master', \"local[*]\")\n",
    "data_dir = os.environ.get('data_dir', './component-library/data/')\n",
    "\n",
    "data_parquet = 'data.parquet'\n",
    "data_csv = 'data.csv'\n",
    "\n",
    "skip = False\n",
    "if os.path.exists(data_dir + data_csv):\n",
    "    skip = True\n",
    "\n",
    "if not skip:\n",
    "    sc = SparkContext.getOrCreate(SparkConf().setMaster(master))\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.read.parquet(data_dir + data_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0badfa9a-1547-4298-9634-55550fc51703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the parquet file to CSV format.\n",
    "if not skip:\n",
    "    if os.path.exists(data_dir + data_csv):\n",
    "        shutil.rmtree(data_dir + data_csv)\n",
    "    df.coalesce(1).write.option(\"header\", \"true\").csv(data_dir + data_csv)\n",
    "    file = glob.glob(data_dir + data_csv + '/part-*')\n",
    "    shutil.move(file[0], data_dir + data_csv + '.tmp')\n",
    "    shutil.rmtree(data_dir + data_csv)\n",
    "    shutil.move(data_dir + data_csv + '.tmp', data_dir + data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58315de5-2407-4edd-9cf3-6dce22dc2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 80-20 training and test split with seed=1.\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f922f17e-5714-4def-9090-e7387c6ed5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"x\", df.x.cast(DoubleType()))\n",
    "df = df.withColumn(\"y\", df.y.cast(DoubleType()))\n",
    "df = df.withColumn(\"z\", df.z.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "588e1a04-55c7-4d42-853d-52ba4adc2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.8, 0.2], 1)\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5cd4da35-1be0-44a6-b295-e06174221701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model with different hyperparameters listed below and report the best performing hyperparameter combinations.\n",
    "input_columns = os.environ.get('input_columns',\n",
    "                               '[\"x\", \"y\", \"z\"]')  # input columns to consider\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=eval(input_columns),\n",
    "                                  outputCol=\"features\")\n",
    "\n",
    "normalizer = MinMaxScaler(inputCol=\"features\", outputCol=\"features_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d49d6bc-cf5a-4432-a438-88de82f74866",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(numTrees=10, maxDepth=5, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39cc305d-6b99-450e-bf2e-d26b2585c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a006576-2121-4b36-a5e9-704705edaf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2143828c-74ad-45b2-ad4e-e26cbf934b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0a4094f-d699-4d36-bf8a-fbd765a68fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44382182942402043"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binEval = MulticlassClassificationEvaluator(). \\\n",
    "    setMetricName(\"accuracy\"). \\\n",
    "    setPredictionCol(\"prediction\"). \\\n",
    "    setLabelCol(\"label\")\n",
    "\n",
    "binEval.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036aa3c6-fe61-429c-8e51-d8df5df51a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
